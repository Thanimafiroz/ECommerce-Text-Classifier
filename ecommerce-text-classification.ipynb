{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom sklearn.metrics import f1_score, classification_report\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom transformers import BertTokenizer, BertForSequenceClassification\nfrom transformers import Trainer, TrainingArguments\nfrom transformers import EarlyStoppingCallback\nimport torch\nfrom tqdm import tqdm\nimport os\nos.environ[\"WANDB_DISABLED\"] = \"true\"","metadata":{"_uuid":"60e19d3a-7fdc-4c38-a792-8e1e2e6d2fff","_cell_guid":"83908799-a58e-4b5b-b511-33c75444736b","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-09-18T13:14:23.554149Z","iopub.execute_input":"2022-09-18T13:14:23.554864Z","iopub.status.idle":"2022-09-18T13:14:32.099733Z","shell.execute_reply.started":"2022-09-18T13:14:23.554768Z","shell.execute_reply":"2022-09-18T13:14:32.098711Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"def get_batch_tokenizer(tokenizer, dataset):\n    return tokenizer.batch_encode_plus(dataset,\n                                       max_length=256,\n                                       padding=True,\n                                       truncation=True,\n                                       add_special_tokens=True,\n                                       return_attention_mask=True,\n                                       return_tensors='pt')\n","metadata":{"execution":{"iopub.status.busy":"2022-09-18T13:14:32.101693Z","iopub.execute_input":"2022-09-18T13:14:32.102337Z","iopub.status.idle":"2022-09-18T13:14:32.108300Z","shell.execute_reply.started":"2022-09-18T13:14:32.102301Z","shell.execute_reply":"2022-09-18T13:14:32.107222Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"class Dataset(torch.utils.data.Dataset):\n    def __init__(self, encodings, labels):\n        self.encodings = encodings\n        self.labels = labels\n\n    def __getitem__(self, idx):\n        item = {key: torch.tensor(val[idx]) for key, val\n                in self.encodings.items()}\n        item['labels'] = torch.tensor(self.labels[idx])\n        return item\n\n    def __len__(self):\n        return len(self.labels)","metadata":{"execution":{"iopub.status.busy":"2022-09-18T13:14:32.109546Z","iopub.execute_input":"2022-09-18T13:14:32.110507Z","iopub.status.idle":"2022-09-18T13:14:32.119059Z","shell.execute_reply.started":"2022-09-18T13:14:32.110463Z","shell.execute_reply":"2022-09-18T13:14:32.118060Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"def compute_metrics(p):\n    prediction, labels = p\n    preds_flat = np.argmax(prediction, axis=1).flatten()\n    labels_flat = labels.flatten()\n    f1 = f1_score(labels_flat, preds_flat, average='macro')\n    return {\"f1\": f1}","metadata":{"execution":{"iopub.status.busy":"2022-09-18T13:14:32.121759Z","iopub.execute_input":"2022-09-18T13:14:32.122110Z","iopub.status.idle":"2022-09-18T13:14:32.129894Z","shell.execute_reply.started":"2022-09-18T13:14:32.122076Z","shell.execute_reply":"2022-09-18T13:14:32.128901Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(\"../input/ecommerce-text-classification/ecommerceDataset.csv\", names=[\"labels\", \"descriptions\"])\ndescriptions = df[\"descriptions\"].map(str).values.tolist()\nlabels = df[\"labels\"].values.tolist()\n\nle = LabelEncoder()\nlabels = le.fit_transform(labels).tolist()","metadata":{"execution":{"iopub.status.busy":"2022-09-18T13:14:32.131311Z","iopub.execute_input":"2022-09-18T13:14:32.131673Z","iopub.status.idle":"2022-09-18T13:14:33.034124Z","shell.execute_reply.started":"2022-09-18T13:14:32.131636Z","shell.execute_reply":"2022-09-18T13:14:33.033129Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"model = BertForSequenceClassification.from_pretrained(\n    \"bert-base-uncased\",\n    num_labels=4)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)","metadata":{"execution":{"iopub.status.busy":"2022-09-18T13:14:33.035546Z","iopub.execute_input":"2022-09-18T13:14:33.035913Z","iopub.status.idle":"2022-09-18T13:14:48.224286Z","shell.execute_reply.started":"2022-09-18T13:14:33.035877Z","shell.execute_reply":"2022-09-18T13:14:48.223272Z"},"trusted":true},"execution_count":6,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/570 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3b688ef3f2e442c4b639c3df1a85f02f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/420M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0fa9f3bdda134a478b6903fd67dc5de5"}},"metadata":{}},{"name":"stderr","text":"Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias']\n- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"BertForSequenceClassification(\n  (bert): BertModel(\n    (embeddings): BertEmbeddings(\n      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n      (position_embeddings): Embedding(512, 768)\n      (token_type_embeddings): Embedding(2, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): BertEncoder(\n      (layer): ModuleList(\n        (0): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (1): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (2): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (3): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (4): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (5): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (6): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (7): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (8): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (9): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (10): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (11): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (pooler): BertPooler(\n      (dense): Linear(in_features=768, out_features=768, bias=True)\n      (activation): Tanh()\n    )\n  )\n  (dropout): Dropout(p=0.1, inplace=False)\n  (classifier): Linear(in_features=768, out_features=4, bias=True)\n)"},"metadata":{}}]},{"cell_type":"code","source":"tokenizer = BertTokenizer.from_pretrained(\n        \"bert-base-uncased\",\n        do_lower_case=True)","metadata":{"execution":{"iopub.status.busy":"2022-09-18T13:14:48.225825Z","iopub.execute_input":"2022-09-18T13:14:48.226206Z","iopub.status.idle":"2022-09-18T13:14:49.155516Z","shell.execute_reply.started":"2022-09-18T13:14:48.226169Z","shell.execute_reply":"2022-09-18T13:14:49.154499Z"},"trusted":true},"execution_count":7,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9953f35acf814ff2a70442df2e379e40"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"84531978803b475a9d36ccd382386fb4"}},"metadata":{}}]},{"cell_type":"code","source":"x_train, x_test, y_train, y_test = train_test_split(descriptions, labels, test_size=0.4, stratify=labels, random_state=42)\nx_valid, x_test, y_valid, y_test = train_test_split(x_test, y_test, test_size=0.5, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2022-09-18T13:14:49.156893Z","iopub.execute_input":"2022-09-18T13:14:49.157629Z","iopub.status.idle":"2022-09-18T13:14:49.795370Z","shell.execute_reply.started":"2022-09-18T13:14:49.157572Z","shell.execute_reply":"2022-09-18T13:14:49.794434Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"x_train_tokens = get_batch_tokenizer(tokenizer, x_train)\nx_valid_tokens = get_batch_tokenizer(tokenizer, x_valid)\nx_test_tokens = get_batch_tokenizer(tokenizer, x_test)","metadata":{"execution":{"iopub.status.busy":"2022-09-18T13:14:49.796645Z","iopub.execute_input":"2022-09-18T13:14:49.796985Z","iopub.status.idle":"2022-09-18T13:17:49.707176Z","shell.execute_reply.started":"2022-09-18T13:14:49.796952Z","shell.execute_reply":"2022-09-18T13:17:49.706173Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"train_dataset = Dataset(x_train_tokens, y_train)\nvalid_dataset = Dataset(x_valid_tokens, y_valid)\ntest_dataset = Dataset(x_test_tokens, y_test)","metadata":{"execution":{"iopub.status.busy":"2022-09-18T13:17:49.710808Z","iopub.execute_input":"2022-09-18T13:17:49.711199Z","iopub.status.idle":"2022-09-18T13:17:49.716011Z","shell.execute_reply.started":"2022-09-18T13:17:49.711166Z","shell.execute_reply":"2022-09-18T13:17:49.714969Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"args = TrainingArguments(output_dir=\"output\",\n                            evaluation_strategy=\"epoch\",\n                            metric_for_best_model=\"f1\",\n                            save_strategy=\"epoch\",\n                            num_train_epochs=3,\n                            load_best_model_at_end=True\n                            )","metadata":{"execution":{"iopub.status.busy":"2022-09-18T13:17:49.717620Z","iopub.execute_input":"2022-09-18T13:17:49.718009Z","iopub.status.idle":"2022-09-18T13:17:49.730296Z","shell.execute_reply.started":"2022-09-18T13:17:49.717973Z","shell.execute_reply":"2022-09-18T13:17:49.729195Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stderr","text":"Using the `WAND_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n","output_type":"stream"}]},{"cell_type":"code","source":"trainer = Trainer(args=args,\n                    model=model,\n                    train_dataset=train_dataset,\n                    eval_dataset=valid_dataset,\n                    compute_metrics=compute_metrics,\n                    callbacks=[EarlyStoppingCallback(\n                            early_stopping_patience=3)]\n                    )","metadata":{"execution":{"iopub.status.busy":"2022-09-18T13:17:49.731533Z","iopub.execute_input":"2022-09-18T13:17:49.732459Z","iopub.status.idle":"2022-09-18T13:17:49.758071Z","shell.execute_reply.started":"2022-09-18T13:17:49.732424Z","shell.execute_reply":"2022-09-18T13:17:49.757182Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"trainer.train()","metadata":{"execution":{"iopub.status.busy":"2022-09-18T13:17:49.759496Z","iopub.execute_input":"2022-09-18T13:17:49.759916Z","iopub.status.idle":"2022-09-18T14:03:33.479599Z","shell.execute_reply.started":"2022-09-18T13:17:49.759881Z","shell.execute_reply":"2022-09-18T14:03:33.478327Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  FutureWarning,\n***** Running training *****\n  Num examples = 30255\n  Num Epochs = 3\n  Instantaneous batch size per device = 8\n  Total train batch size (w. parallel, distributed & accumulation) = 8\n  Gradient Accumulation steps = 1\n  Total optimization steps = 11346\n/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  import sys\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='11346' max='11346' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [11346/11346 45:42, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>F1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.188400</td>\n      <td>0.188548</td>\n      <td>0.968506</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.090800</td>\n      <td>0.166719</td>\n      <td>0.974241</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.056700</td>\n      <td>0.136571</td>\n      <td>0.979119</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"***** Running Evaluation *****\n  Num examples = 10085\n  Batch size = 8\nSaving model checkpoint to output/checkpoint-3782\nConfiguration saved in output/checkpoint-3782/config.json\nModel weights saved in output/checkpoint-3782/pytorch_model.bin\n/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  import sys\n***** Running Evaluation *****\n  Num examples = 10085\n  Batch size = 8\nSaving model checkpoint to output/checkpoint-7564\nConfiguration saved in output/checkpoint-7564/config.json\nModel weights saved in output/checkpoint-7564/pytorch_model.bin\n/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  import sys\n***** Running Evaluation *****\n  Num examples = 10085\n  Batch size = 8\nSaving model checkpoint to output/checkpoint-11346\nConfiguration saved in output/checkpoint-11346/config.json\nModel weights saved in output/checkpoint-11346/pytorch_model.bin\n\n\nTraining completed. Do not forget to share your model on huggingface.co/models =)\n\n\nLoading best model from output/checkpoint-11346 (score: 0.9791193944241369).\n","output_type":"stream"},{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=11346, training_loss=0.13670388206106718, metrics={'train_runtime': 2743.6764, 'train_samples_per_second': 33.082, 'train_steps_per_second': 4.135, 'total_flos': 1.194085189020672e+16, 'train_loss': 0.13670388206106718, 'epoch': 3.0})"},"metadata":{}}]},{"cell_type":"code","source":"trainer = Trainer(model=model)\npredictions = trainer.predict(test_dataset)","metadata":{"execution":{"iopub.status.busy":"2022-09-18T14:03:33.485365Z","iopub.execute_input":"2022-09-18T14:03:33.488530Z","iopub.status.idle":"2022-09-18T14:04:55.261772Z","shell.execute_reply.started":"2022-09-18T14:03:33.488485Z","shell.execute_reply":"2022-09-18T14:04:55.260735Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stderr","text":"No `TrainingArguments` passed, using `output_dir=tmp_trainer`.\nPyTorch: setting up devices\nThe default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\nUsing the `WAND_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n***** Running Prediction *****\n  Num examples = 10085\n  Batch size = 8\n/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  import sys\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='1261' max='1261' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [1261/1261 01:21]\n    </div>\n    "},"metadata":{}}]},{"cell_type":"code","source":"preds = np.argmax(predictions.predictions, axis=1).flatten()\ntrue_vals = predictions.label_ids","metadata":{"execution":{"iopub.status.busy":"2022-09-18T14:04:55.263301Z","iopub.execute_input":"2022-09-18T14:04:55.263670Z","iopub.status.idle":"2022-09-18T14:04:55.289583Z","shell.execute_reply.started":"2022-09-18T14:04:55.263633Z","shell.execute_reply":"2022-09-18T14:04:55.288690Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"print(classification_report(true_vals, preds, target_names=list(le.classes_)))","metadata":{"execution":{"iopub.status.busy":"2022-09-18T14:04:55.291000Z","iopub.execute_input":"2022-09-18T14:04:55.291888Z","iopub.status.idle":"2022-09-18T14:04:55.318330Z","shell.execute_reply.started":"2022-09-18T14:04:55.291851Z","shell.execute_reply":"2022-09-18T14:04:55.317235Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"                        precision    recall  f1-score   support\n\n                 Books       0.98      0.97      0.98      2335\nClothing & Accessories       0.99      0.99      0.99      1772\n           Electronics       0.97      0.97      0.97      2111\n             Household       0.98      0.99      0.98      3867\n\n              accuracy                           0.98     10085\n             macro avg       0.98      0.98      0.98     10085\n          weighted avg       0.98      0.98      0.98     10085\n\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}